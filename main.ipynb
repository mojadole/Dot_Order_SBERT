{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "음식 데이터 수 :  46\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food_name</th>\n",
       "      <th>food_category</th>\n",
       "      <th>food_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>야채김밥</td>\n",
       "      <td>김밥</td>\n",
       "      <td>김에 밥과 다양한 야채를 넣어서 만든 한국의 전통적인 간단한 김밥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>치즈김밥</td>\n",
       "      <td>김밥</td>\n",
       "      <td>김에 밥과 치즈를 넣어서 만든 인기 있는 한국의 간단한 김밥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>소고기김밥</td>\n",
       "      <td>김밥</td>\n",
       "      <td>김에 밥과 소고기, 야채 등을 넣어서 만든 한국의 대표적인 김밥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>매콤오징어김밥</td>\n",
       "      <td>김밥</td>\n",
       "      <td>오징어와 야채를 매콤한 양념으로 볶아 김에 싸서 만든, 한국의 대표적인 매운 김밥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>매콤땡+A1초김밥</td>\n",
       "      <td>김밥</td>\n",
       "      <td>김에 밥과 매콤한 땡초와 함께 참치, 소세지 등을 넣어서 만든, 한국의 대표적인 매...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   food_name food_category                                   food_description\n",
       "0       야채김밥            김밥               김에 밥과 다양한 야채를 넣어서 만든 한국의 전통적인 간단한 김밥\n",
       "1       치즈김밥            김밥                  김에 밥과 치즈를 넣어서 만든 인기 있는 한국의 간단한 김밥\n",
       "2      소고기김밥            김밥                김에 밥과 소고기, 야채 등을 넣어서 만든 한국의 대표적인 김밥\n",
       "3    매콤오징어김밥            김밥      오징어와 야채를 매콤한 양념으로 볶아 김에 싸서 만든, 한국의 대표적인 매운 김밥\n",
       "4  매콤땡+A1초김밥            김밥  김에 밥과 매콤한 땡초와 함께 참치, 소세지 등을 넣어서 만든, 한국의 대표적인 매..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from key_extraction import keywordExtractor\n",
    "from transformers import ElectraModel, ElectraTokenizerFast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# load model and tokenizer\n",
    "name = \"monologg/koelectra-base-v3-discriminator\"\n",
    "model = ElectraModel.from_pretrained(name)\n",
    "tokenizer = ElectraTokenizerFast.from_pretrained(name)\n",
    "\n",
    "# load keywordExtractor\n",
    "key = keywordExtractor(model,tokenizer,dir='data/preprocess/eng_han.csv')\n",
    "\n",
    "# load food data\n",
    "scraping_result = pd.read_csv('data/food_data.csv',encoding='cp949')\n",
    "print('음식 데이터 수 : ', len(scraping_result))\n",
    "print('')\n",
    "scraping_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Tuple, List, Dict\n",
    "from itertools import chain, islice\n",
    "import torch\n",
    "\n",
    "def _convert_series_to_list_in_main(series: pd.Series) -> List[List[str]]:\n",
    "\n",
    "\traw_data = list(series.values)\n",
    "\treturn list(chain(*map(lambda x: x.split(), raw_data)))\n",
    "\n",
    "\n",
    "def extract_keyword_list_in_main(doc: pd.Series, min_count: int = 2, min_length: int = 2) -> List:\n",
    "\n",
    "\traw_data = _convert_series_to_list_in_main(doc)\n",
    "\tkeyword_list = key._extract_keywords(raw_data)\n",
    "\ttranslated_keyword_list = key._map_english_to_korean(keyword_list)\n",
    "\trefined_keyword_list = key._eliminate_min_count_words(translated_keyword_list, min_count)\n",
    "\treturn list(filter(lambda x: len(x) >= min_length, refined_keyword_list))\n",
    "\n",
    "def create_keyword_embedding_in_main(doc: pd.Series) -> torch.Tensor:\n",
    "\n",
    "\tkeyword_list = extract_keyword_list_in_main(doc)\n",
    "\ttokenized_keyword = key.tokenize_keyword(keyword_list)\n",
    "\treturn key._create_keyword_embedding(tokenized_keyword)\n",
    "\n",
    "def create_doc_embedding_in_main(doc: pd.Series) -> torch.Tensor:\n",
    "\n",
    "\tstringified_doc = _convert_series_to_str_in_main(doc)\n",
    "\ttokenized_doc = key.tokenize_keyword(stringified_doc)\n",
    "\treturn key._create_doc_embedding(tokenized_doc)\n",
    "\n",
    "def _convert_series_to_str_in_main(series: pd.Series) -> str:\n",
    "\n",
    "\treturn \" \".join(list(series.values))\n",
    "\n",
    "def keyword_(num):\n",
    "    min_count = 2\n",
    "    min_length = 1\n",
    "\n",
    "    doc = scraping_result.iloc[num]\n",
    "    \n",
    "    raw_data = _convert_series_to_list_in_main(doc)\n",
    "    keyword_list = key._extract_keywords(raw_data)\n",
    "    translated_keyword_list = key._map_english_to_korean(keyword_list)\n",
    "    refined_keyword_list = key._eliminate_min_count_words(translated_keyword_list, min_count)\n",
    "    result = list(filter(lambda x: len(x) >= min_length, refined_keyword_list))\n",
    "    return (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. 음식 정보를 list로 통합 -> 12 개 단어\n",
      "['야채김밥', '김밥', '김에', '밥과', '다양한', '야채를', '넣어서', '만든', '한국의', '전통적인'].... \n",
      "\n",
      "['야채김밥', '김밥', '김에', '밥과', '다양한', '야채를', '넣어서', '만든', '한국의', '전통적인', '간단한', '김밥']\n",
      "2. 형태소 분석기를 활용해 명사만을 추출 -> 10 개 단어\n",
      "['야채', '김밥', '김밥', '김', '밥', '다양', '야채', '한국', '전통', '김밥'].... \n",
      "\n",
      "3. 영단어를 한글로 변환(ex python -> 파이썬) -> 10 개 단어\n",
      "['야채', '김밥', '김밥', '김', '밥', '다양', '야채', '한국', '전통', '김밥'].... \n",
      "\n",
      "4. 최소 2번이상 반복 사용되는 단어만 추출 -> 2 개 단어\n",
      "['야채', '김밥'].... \n",
      "\n",
      "5. 단어 길이가 최소 한개 이상인 단어만 추출 -> 2 개 단어\n",
      "['야채', '김밥'].... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "min_count = 2\n",
    "min_length = 1\n",
    "doc = scraping_result.iloc[0]\n",
    "\n",
    "#print(f'음식 정보 \\n \\n {doc} \\n \\n')\n",
    "\n",
    "## raw_data = key._convert_series_to_list(doc)\n",
    "raw_data = _convert_series_to_list_in_main(doc) ## key_extraction 말고 새롭게 선언하면 에러 안 생김 (왜지 도대체) + 단어가 제대로 나뉘지 않아서 수정함\n",
    "\n",
    "print(f'\\n1. 음식 정보를 list로 통합 -> {len(raw_data)} 개 단어')\n",
    "print(f'{raw_data[:10]}.... \\n')\n",
    "print(raw_data)\n",
    "\n",
    "keyword_list = key._extract_keywords(raw_data)\n",
    "print(f'2. 형태소 분석기를 활용해 명사만을 추출 -> {len(keyword_list)} 개 단어')\n",
    "print(f'{keyword_list[:10]}.... \\n')\n",
    "\n",
    "translated_keyword_list = key._map_english_to_korean(keyword_list)\n",
    "print(f'3. 영단어를 한글로 변환(ex python -> 파이썬) -> {len(translated_keyword_list)} 개 단어')\n",
    "print(f'{translated_keyword_list[:10]}.... \\n')\n",
    "\n",
    "refined_keyword_list = key._eliminate_min_count_words(translated_keyword_list, min_count)\n",
    "print(f'4. 최소 2번이상 반복 사용되는 단어만 추출 -> {len(refined_keyword_list)} 개 단어')\n",
    "print(f'{refined_keyword_list[:10]}.... \\n')\n",
    "\n",
    "result = list(filter(lambda x: len(x) >= min_length, refined_keyword_list))\n",
    "print(f'5. 단어 길이가 최소 한개 이상인 단어만 추출 -> {len(result)} 개 단어')\n",
    "print(f'{result[:10]}.... \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 메뉴명 -- \n",
      " 야채김밥 \n",
      " \n",
      "\n",
      "음식에 대한 키워드 후보 : 2 개 단어\n",
      "['야채', '김밥'].... \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "doc = scraping_result.iloc[0]\n",
    "\n",
    "print(f'-- 메뉴명 -- \\n {doc.food_name} \\n \\n')\n",
    "\n",
    "keyword_list = extract_keyword_list_in_main(doc)\n",
    "print(f'음식에 대한 키워드 후보 : {len(result)} 개 단어')\n",
    "print(f'{result[:10]}.... \\n \\n')\n",
    "\n",
    "## keyword_embedding = key.create_keyword_embedding(doc)\n",
    "keyword_embedding = create_keyword_embedding_in_main(doc)\n",
    "## doc_embedding = key.create_doc_embedding(doc)\n",
    "doc_embedding = create_doc_embedding_in_main(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 키워드 추출 결과(20개 요약)--\n",
      "[('야채', 0.85827744), ('김밥', 0.8466986)]\n"
     ]
    }
   ],
   "source": [
    "co_sim_score =key._calc_cosine_similarity(doc_embedding, keyword_embedding).flatten()\n",
    "\n",
    "keyword = dict(zip(keyword_list, co_sim_score))\n",
    "\n",
    "sorted_keyword = sorted(keyword.items(), key=lambda k: k[1], reverse=True)\n",
    "\n",
    "print(f'-- 키워드 추출 결과(20개 요약)--')\n",
    "pprint(sorted_keyword[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['야채', '김밥'], ['치즈', '김밥'], ['소고기', '김밥'], ['오징어', '김밥'], ['김밥'], ['김밥'], ['참치', '와사비', '김밥'], ['새우', '날치', '알', '김밥'], ['어린이', '김밥'], ['찌개'], ['찌개', '돼지고기', '맛'], ['찌개'], ['찌개', '참치', '김치', '맛'], ['고등어', '찌개', '김치', '맛'], ['꽁치', '찌개', '김치', '맛'], ['국'], ['뚝배기', '불고기'], ['김치', '볶음밥', '밥'], ['카레', '덮밥', '밥'], ['덮밥', '밥'], ['참치', '볶음밥'], ['야채', '비빔밥', '밥'], ['밥'], ['햄', '야채', '볶음밥', '밥'], ['새우', '볶음밥', '밥'], ['새우', '날치', '알', '볶음밥', '밥'], ['밥'], ['면'], ['콩나물', '라면'], ['떡', '라면'], ['치즈', '면'], ['만두', '면', '라면'], ['국물'], ['국물'], ['부산', '오뎅'], ['부산', '면'], [], ['김치', '만두', '분식'], ['물'], ['밥'], ['국'], ['떡', '국'], ['면'], ['등심', '돈까스'], ['치즈', '돈까스', '맛'], ['돈까스']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'### 피클 파일로 저장 ###\\nwith open(\"food_data.pickle\",\"wb\") as fw:\\n    pickle.dump(food_list, fw)\\n \\n### 피클 파일 불러오기 ###\\nwith open(\"food_data.pickle\",\"rb\") as fr:\\n    food_data = pickle.load(fr)\\n\\nprint(food_data)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from gensim.models import keyedvectors\n",
    "import pickle\n",
    "\n",
    "food_name = []\n",
    "food_keyword = []\n",
    "\n",
    "for i in range(len(scraping_result)):\n",
    "    food_name.append(scraping_result.iloc[i].food_name)\n",
    "    food_keyword.append(keyword_(i))\n",
    "\n",
    "print(food_keyword)\n",
    "\n",
    "# numpy 배열로 변경\n",
    "#food_name = np.array(food_name)\n",
    "#food_keyword = np.array(food_keyword, dtype=list)\n",
    "\n",
    "#food_list = [food_name, food_keyword]\n",
    "\n",
    "# 굳이 피클로 저장 안 해도 될 듯 (속도 때문에 그런 것 같음)\n",
    "\"\"\"### 피클 파일로 저장 ###\n",
    "with open(\"food_data.pickle\",\"wb\") as fw:\n",
    "    pickle.dump(food_list, fw)\n",
    " \n",
    "### 피클 파일 불러오기 ###\n",
    "with open(\"food_data.pickle\",\"rb\") as fr:\n",
    "    food_data = pickle.load(fr)\n",
    "\n",
    "print(food_data)\"\"\"\n",
    "\n",
    "#pd.DataFrame([food_name,food_keyword]).T.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 검색 키워드 :  ['돈까스']\n",
      "\n",
      "<class 'numpy.int64'>\n",
      "키워드에 따른 상위 20개 음식 추천 결과\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food_name</th>\n",
       "      <th>food_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>수제왕돈까스</td>\n",
       "      <td>튀김</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>치즈돈까스</td>\n",
       "      <td>튀김</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>등심돈까스</td>\n",
       "      <td>튀김</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>소고기김밥</td>\n",
       "      <td>김밥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>야채비빔밥</td>\n",
       "      <td>밥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>참치볶음밥</td>\n",
       "      <td>밥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>제육덮밥</td>\n",
       "      <td>밥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>카레덮밥</td>\n",
       "      <td>밥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>김치볶음밥</td>\n",
       "      <td>밥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>뚝배기불고기</td>\n",
       "      <td>국</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>치즈김밥</td>\n",
       "      <td>김밥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>꽁치김치찌개</td>\n",
       "      <td>찌개</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>고등어김치찌개</td>\n",
       "      <td>찌개</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>참치김치찌개</td>\n",
       "      <td>찌개</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>순두부찌개</td>\n",
       "      <td>찌개</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>된장찌개</td>\n",
       "      <td>찌개</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>어린이김밥</td>\n",
       "      <td>김밥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>새우날치알김밥</td>\n",
       "      <td>김밥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>참치와사비김밥</td>\n",
       "      <td>김밥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>육개장</td>\n",
       "      <td>국</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   food_name food_category\n",
       "0     수제왕돈까스            튀김\n",
       "1      치즈돈까스            튀김\n",
       "2      등심돈까스            튀김\n",
       "3      소고기김밥            김밥\n",
       "4      야채비빔밥             밥\n",
       "5      참치볶음밥             밥\n",
       "6       제육덮밥             밥\n",
       "7       카레덮밥             밥\n",
       "8      김치볶음밥             밥\n",
       "9     뚝배기불고기             국\n",
       "10      치즈김밥            김밥\n",
       "11    꽁치김치찌개            찌개\n",
       "12   고등어김치찌개            찌개\n",
       "13    참치김치찌개            찌개\n",
       "14     순두부찌개            찌개\n",
       "15      된장찌개            찌개\n",
       "16     어린이김밥            김밥\n",
       "17   새우날치알김밥            김밥\n",
       "18   참치와사비김밥            김밥\n",
       "19       육개장             국"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np  \n",
    "\n",
    "# 키워드 검색\n",
    "search = ['돈까스'] # 입력 -> 키워드\n",
    "#search = np.array(search)\n",
    "print('사용자 검색 키워드 : ', search)\n",
    "print('')\n",
    "\n",
    "\"\"\"# 키워드 확장 \n",
    "recommand_keyword = w2v_model.most_similar(positive=search, topn=15)\n",
    "np_recommand_keyword = np.array(list(map(lambda x: x[0], recommand_keyword)))\n",
    "print('W2V을 활용한 키워드 확장 :', np_recommand_keyword)\n",
    "print('')\"\"\"\n",
    "\n",
    "\n",
    "# 키워드와 유사한 도서 검색 \n",
    "\n",
    "user_point = [int(0)] * len(food_name)\n",
    "\n",
    "for search_key in search:\n",
    "    for i in range(len(food_name)):\n",
    "        if search_key in food_keyword[i]:\n",
    "            user_point[i] = user_point[i] + int(1)\n",
    "\n",
    "\n",
    "#user_point = np.isin(food_keyword, np.array(search)).sum(axis=1)\n",
    "#recommand_point = np.isin(food_keyword, np_recommand_keyword).sum(axis=1)\n",
    "\n",
    "#total_point = (user_point * 3) + recommand_point\n",
    "total_point = user_point\n",
    "top_k_idx = np.argsort(total_point)[::-1][:20]\n",
    "\n",
    "print(type(top_k_idx[0]))\n",
    "\n",
    "# 메뉴명 연관 점수 저장\n",
    "food_name = np.array(food_name)\n",
    "total_point = np.array(total_point)\n",
    "\n",
    "result  = dict(zip(food_name[top_k_idx], total_point[top_k_idx]))\n",
    "\n",
    "# 음식 정보 추출\n",
    "food_info = pd.read_csv('data/food_data.csv',encoding='cp949')\n",
    "IDX = food_info.food_name.isin(list(result.keys()))\n",
    "\n",
    "food_recommandation_result = food_info[[\"food_name\", \"food_category\"]][IDX].sort_values(\n",
    "    by=\"food_name\", key=lambda x: x.map(result), ascending=False\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print('키워드에 따른 상위 20개 음식 추천 결과')\n",
    "pd.DataFrame(food_recommandation_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
