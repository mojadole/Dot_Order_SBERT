{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 클래스, 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "음식 데이터 수 :  47\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food_name</th>\n",
       "      <th>food_category</th>\n",
       "      <th>food_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>라면</td>\n",
       "      <td>면</td>\n",
       "      <td>라면은 아시아에서 유명한 인스턴트 면 요리로, 면과 스프로 구성됩니다. 면은 탄력이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>야채김밥</td>\n",
       "      <td>김밥</td>\n",
       "      <td>김에 밥과 다양한 야채를 넣어서 만든 한국의 전통적인 간단한 김밥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>치즈김밥</td>\n",
       "      <td>김밥</td>\n",
       "      <td>김에 밥과 치즈를 넣어서 만든 인기 있는 한국의 간단한 김밥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>소고기김밥</td>\n",
       "      <td>김밥</td>\n",
       "      <td>김에 밥과 소고기, 야채 등을 넣어서 만든 한국의 대표적인 김밥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>매콤오징어김밥</td>\n",
       "      <td>김밥</td>\n",
       "      <td>오징어와 야채를 매콤한 양념으로 볶아 김에 싸서 만든, 한국의 대표적인 매운 김밥</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  food_name food_category                                   food_description\n",
       "0        라면             면  라면은 아시아에서 유명한 인스턴트 면 요리로, 면과 스프로 구성됩니다. 면은 탄력이...\n",
       "1      야채김밥            김밥               김에 밥과 다양한 야채를 넣어서 만든 한국의 전통적인 간단한 김밥\n",
       "2      치즈김밥            김밥                  김에 밥과 치즈를 넣어서 만든 인기 있는 한국의 간단한 김밥\n",
       "3     소고기김밥            김밥                김에 밥과 소고기, 야채 등을 넣어서 만든 한국의 대표적인 김밥\n",
       "4   매콤오징어김밥            김밥      오징어와 야채를 매콤한 양념으로 볶아 김에 싸서 만든, 한국의 대표적인 매운 김밥"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from key_extraction import keywordExtractor\n",
    "from transformers import ElectraModel, ElectraTokenizerFast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Union, Tuple, List, Dict\n",
    "from itertools import chain, islice\n",
    "import torch\n",
    "import openai\n",
    "from gensim.models import keyedvectors\n",
    "import pickle\n",
    "\n",
    "# load model and tokenizer\n",
    "name = \"monologg/koelectra-base-v3-discriminator\"\n",
    "model = ElectraModel.from_pretrained(name)\n",
    "tokenizer = ElectraTokenizerFast.from_pretrained(name)\n",
    "\n",
    "# load keywordExtractor\n",
    "key = keywordExtractor(model,tokenizer,dir='data/preprocess/eng_han.csv')\n",
    "\n",
    "# load food data\n",
    "scraping_result = pd.read_csv('data/food_data.csv',encoding='cp949')\n",
    "#scraping_result = pd.read_csv('data/food_data2.csv')\n",
    "print('음식 데이터 수 : ', len(scraping_result))\n",
    "print('')\n",
    "scraping_result.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 함수 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################### 따로 만든 함수 #####################################\n",
    "API_KEY = 'sk-' ####### 키\n",
    "\n",
    "# chatGPT API 사용 함수\n",
    "def callChatGPT(prompt, API_KEY=API_KEY):\n",
    "    \n",
    "    messages = []\n",
    "\n",
    "    #get api key\n",
    "    openai.api_key = API_KEY\n",
    "\n",
    "    messages.append({\"role\":\"user\", \"content\":prompt})\n",
    "\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages\n",
    "    )\n",
    "    chat_response = completion.choices[0].message.content\n",
    "    messages.append({\"role\":\"assitant\", \"content\":chat_response})\n",
    "\n",
    "    return messages[1][\"content\"]\n",
    "\n",
    "# chatGPT한테 필요한 데이터 얻는 함수\n",
    "def obtain_data(menu_name):\n",
    "\n",
    "    #chat_res_cat = callChatGPT(menu_name + \" 는 [밥], [국], [면], [분식] 중에 뭐야\")\n",
    "    #chat_res_cat = chat_res_cat[chat_res_cat.find('[')+1:chat_res_cat.find(']')] # GPT 답변 : 메뉴 카테고리\n",
    "\n",
    "    #chat_res_des = callChatGPT(menu_name + \"에 대한 간단한 설명\") # GPT 답변 : 메뉴 설명\n",
    "\n",
    "    menu_name = \"라면\"\n",
    "    chat_res_cat = \"면\"\n",
    "    chat_res_des = '라면은 아시아에서 유명한 인스턴트 면 요리로, 면과 스프로 구성됩니다. 면은 탄력이 있고 쫄깃하며, 다양한 모양과 두께로 제작됩니다. 스프는 라면의 맛을 결정짓는 중요한 재료로, 다양한 맛과 종류가 있습니다. 라면은 추가 재료로 고기, 해산물, 채소, 계란 등을 넣어 풍부하고 맛있게 즐길 수 있습니다. 라면은 전 세계적으로 인기 있는 음식으로, 맛과 편리함으로 알려져 있습니다.'\n",
    "\n",
    "    #menu_str = menu_name + \" \" + chat_res_cat + \" \" + chat_res_des\n",
    "    menu_str = menu_name + \" \" + chat_res_des\n",
    "    menu_list = menu_str.split()\n",
    "\n",
    "    return menu_list\n",
    "\n",
    "# 새로운 메뉴명 -> 메뉴명, 카테고리, 메뉴설명 -> 키워드 리스트\n",
    "def get_keyword_list(menu_name):\n",
    "    min_count = 2\n",
    "    min_length = 1\n",
    "\n",
    "    raw_data = obtain_data(menu_name) # \n",
    "    keyword_list = key._extract_keywords(raw_data)\n",
    "    translated_keyword_list = key._map_english_to_korean(keyword_list)\n",
    "    refined_keyword_list = key._eliminate_min_count_words(translated_keyword_list, min_count)\n",
    "    result = list(filter(lambda x: len(x) >= min_length, refined_keyword_list))\n",
    "    return (result)\n",
    "\n",
    "# 인덱스 번호 -> 기존 메뉴들 키워드 리스트 가져오기 (지금은 사용 X)\n",
    "def get_keyword_idx(num):\n",
    "    min_count = 2\n",
    "    min_length = 1\n",
    "\n",
    "    doc = scraping_result.iloc[num]\n",
    "  \n",
    "    raw_data = _convert_series_to_list_in_main(doc)\n",
    "    keyword_list = key._extract_keywords(raw_data)\n",
    "    translated_keyword_list = key._map_english_to_korean(keyword_list)\n",
    "    refined_keyword_list = key._eliminate_min_count_words(translated_keyword_list, min_count)\n",
    "    result = list(filter(lambda x: len(x) >= min_length, refined_keyword_list))\n",
    "    return (result)\n",
    "\n",
    "# 기존 메뉴들의 food_name과 각 메뉴들에서 추출한 키워드 뽑아서 초기화하는 함수\n",
    "def init_function():\n",
    "    food_name = []\n",
    "    food_keyword = []\n",
    "\n",
    "    for i in range(len(scraping_result)):\n",
    "        docs_keywords = extract_keyword_in_main(scraping_result.iloc[[i]])\n",
    "        food_name.append(docs_keywords[\"food_name\"][0])\n",
    "        food_keyword.append(docs_keywords[\"keywords\"][0])\n",
    "\n",
    "    return [food_name, food_keyword]\n",
    "\n",
    "# 메뉴 검색하는 함수\n",
    "def search_menu(menu_name, food_name_list, food_keyword_list):\n",
    "    search = get_keyword_list(menu_name) # 입력된 메뉴에서 키워드 추출\n",
    "    print(search)\n",
    "\n",
    "    \"\"\"w2v_model = keyedvectors.load_word2vec_format('data/w2v2')\n",
    "\n",
    "    # 키워드 확장 \n",
    "    recommand_keyword = w2v_model.most_similar(positive=search, topn=15)\n",
    "    np_recommand_keyword = np.array(list(map(lambda x: x[0], recommand_keyword)))\n",
    "    print('W2V을 활용한 키워드 확장 :', np_recommand_keyword)\n",
    "    print('')\"\"\"\n",
    "\n",
    "    # 키워드와 유사한 도서 검색 \n",
    "\n",
    "    user_point = [int(0)] * len(food_name_list)\n",
    "\n",
    "    for search_key in search:\n",
    "        for i in range(len(food_name_list)):\n",
    "            if search_key in food_keyword_list[i]:\n",
    "                user_point[i] = user_point[i] + int(1)\n",
    "\n",
    "\n",
    "    \"\"\"recommand_point = [int(0)] * len(food_name_list)\n",
    "\n",
    "    for search_key in np_recommand_keyword:\n",
    "        for i in range(len(food_name_list)):\n",
    "            \n",
    "            if search_key in food_keyword_list[i]:\n",
    "                recommand_point[i] = recommand_point[i] + int(1)\n",
    "\n",
    "    total_point = [int(0)] * len(user_point)\n",
    "    for i in range(len(user_point)):\n",
    "        total_point[i] = (user_point[i] * 3) + recommand_point[i]\"\"\"\n",
    "    \n",
    "    total_point = user_point\n",
    "\n",
    "    top_k_idx = np.argsort(total_point)[::-1][:20]\n",
    "\n",
    "    # 메뉴명 연관 점수 저장\n",
    "    food_name_list = np.array(food_name_list)\n",
    "    total_point = np.array(total_point)\n",
    "\n",
    "    result  = dict(zip(food_name_list[top_k_idx], total_point[top_k_idx]))\n",
    "\n",
    "    # 음식 정보 추출\n",
    "    food_info = pd.read_csv('data/food_data.csv',encoding='cp949')\n",
    "    IDX = food_info.food_name.isin(list(result.keys()))\n",
    "\n",
    "    food_recommandation_result = food_info[[\"food_name\", \"food_category\"]][IDX].sort_values(\n",
    "        by=\"food_name\", key=lambda x: x.map(result), ascending=False\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return list(food_recommandation_result.food_name)\n",
    "\n",
    "\n",
    "##################################### 기존 함수 수정한 함수 #####################################\n",
    "\n",
    "def extract_keyword_list_in_main(doc: pd.Series, min_count: int = 2, min_length: int = 2) -> List:\n",
    "\n",
    "\traw_data = _convert_series_to_list_in_main(doc)\n",
    "\tkeyword_list = key._extract_keywords(raw_data)\n",
    "\ttranslated_keyword_list = key._map_english_to_korean(keyword_list)\n",
    "\trefined_keyword_list = key._eliminate_min_count_words(translated_keyword_list, min_count)\n",
    "\treturn list(filter(lambda x: len(x) >= min_length, refined_keyword_list))\n",
    "\n",
    "def _convert_series_to_list_in_main(series: pd.Series) -> List[List[str]]:\n",
    "\n",
    "\traw_data = list(series.values)\n",
    "\treturn list(chain(*map(lambda x: x.split(), raw_data)))\n",
    "\n",
    "def create_keyword_embedding_in_main(doc: pd.Series) -> torch.Tensor:\n",
    "\n",
    "\tkeyword_list = extract_keyword_list_in_main(doc)\n",
    "\ttokenized_keyword = key.tokenize_keyword(keyword_list)\n",
    "\treturn key._create_keyword_embedding(tokenized_keyword)\n",
    "\n",
    "def create_doc_embedding_in_main(doc: pd.Series) -> torch.Tensor:\n",
    "\n",
    "\tstringified_doc = _convert_series_to_str_in_main(doc)\n",
    "\ttokenized_doc = key.tokenize_keyword(stringified_doc)\n",
    "\treturn key._create_doc_embedding(tokenized_doc)\n",
    "\n",
    "def _convert_series_to_str_in_main(series: pd.Series) -> str:\n",
    "\treturn \" \".join(list(series.values))\n",
    "\n",
    "def extract_keyword_in_main(docs: pd.DataFrame) -> Dict:\n",
    "\n",
    "\tkeyword_embedding = map(lambda x: create_keyword_embedding_in_main(x[1]), docs.iterrows())\n",
    "\tdoc_embedding = map(lambda x: create_doc_embedding_in_main(x[1]), docs.iterrows())\n",
    "\tkeyword_list = map(lambda x: extract_keyword_list_in_main(x[1]), docs.iterrows())\n",
    "\n",
    "\tco_sim_score = map(\n",
    "\t\tlambda x: key._calc_cosine_similarity(*x).flatten(),\n",
    "\t\tzip(doc_embedding, keyword_embedding),\n",
    "\t)\n",
    "\ttop_n_keyword = list(\n",
    "\t\tmap(lambda x: key._filter_top_n_keyword(*x), zip(keyword_list, co_sim_score))\n",
    "\t)\n",
    "\n",
    "\treturn dict(food_name=docs[\"food_name\"].tolist(), keywords=top_n_keyword)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시작 : 메뉴 입력 + 전체 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "키워드에 따른 상위 20개 음식 추천 결과\n",
      "\n",
      "['라면', '면', '스프', '다양', '맛', '재료']\n",
      "['라면', '라면', '떡라면', '콩나물라면', '만두라면', '어린이김밥', '된장찌개', '돼지김치찌개', '순두부찌개', '참치김치찌개', '매콤땡+A1초김밥', '꽁치김치찌개', '육개장', '뚝배기불고기', '김치볶음밥', '카레덮밥', '참치볶음밥', '새우날치알김밥', '참치와사비김밥', '참치마요김밥', '고등어김치찌개']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'if menu_name in food_name:\\n    print(\"일치하는 메뉴가 있습니다.\")\\n    lst.append(menu_name)\\n\\nelse :\\n    lst = search_menu(menu_name, food_name, food_keyword)\\n\\nif len(lst) == 0:\\n    print(\"해당 메뉴가 없습니다.\")\\nelse:\\n    print(lst)'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "menu_name = \"참치김밥\" ## 입력\n",
    "\n",
    "lst = []\n",
    "\n",
    "with open(\"data/food_name_data.pickle\",\"rb\") as fr:\n",
    "    food_name_list = pickle.load(fr)\n",
    "\n",
    "with open(\"data/food_keyword_data.pickle\",\"rb\") as fr:\n",
    "    food_keyword_list = pickle.load(fr)\n",
    "\n",
    "\"\"\"print('\\n\\n\\n키워드에 따른 상위 20개 음식 추천 결과\\n')\n",
    "print(search_menu(menu_name, food_name_list, food_keyword_list))\"\"\"\n",
    "\n",
    "if menu_name in food_name_list:\n",
    "    print(\"일치하는 메뉴가 있습니다.\")\n",
    "    lst.append(menu_name)\n",
    "\n",
    "else :\n",
    "    lst.append(search_menu(menu_name, food_name_list, food_keyword_list))\n",
    "\n",
    "if len(lst) == 0:\n",
    "    print(\"해당 메뉴가 없습니다.\")\n",
    "else:\n",
    "    print(lst)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 키워드 추출 과정\n",
    "\n",
    "1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. 음식 정보를 list로 통합 -> 53 개 단어\n",
      "['라면', '면', '라면은', '아시아에서', '유명한', '인스턴트', '면', '요리로,', '면과', '스프로'].... \n",
      "\n",
      "2. 형태소 분석기를 활용해 명사만을 추출 -> 37 개 단어\n",
      "['라면', '면', '라면', '아시아', '유명', '인스턴트', '요리', '면', '스프', '구성'].... \n",
      "\n",
      "3. 영단어를 한글로 변환(ex python -> 파이썬) -> 37 개 단어\n",
      "['라면', '면', '라면', '아시아', '유명', '인스턴트', '요리', '면', '스프', '구성'].... \n",
      "\n",
      "4. 최소 2번이상 반복 사용되는 단어만 추출 -> 6 개 단어\n",
      "['라면', '면', '스프', '다양', '맛', '재료'].... \n",
      "\n",
      "5. 단어 길이가 최소 한개 이상인 단어만 추출 -> 6 개 단어\n",
      "['라면', '면', '스프', '다양', '맛', '재료'].... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "min_count = 2\n",
    "min_length = 1\n",
    "doc = scraping_result.iloc[0]\n",
    "\n",
    "#print(f'음식 정보 \\n \\n {doc} \\n \\n')\n",
    "\n",
    "## raw_data = key._convert_series_to_list(doc)\n",
    "raw_data = _convert_series_to_list_in_main(doc)\n",
    "\n",
    "print(f'\\n1. 음식 정보를 list로 통합 -> {len(raw_data)} 개 단어')\n",
    "print(f'{raw_data[:10]}.... \\n')\n",
    "\n",
    "keyword_list = key._extract_keywords(raw_data)\n",
    "print(f'2. 형태소 분석기를 활용해 명사만을 추출 -> {len(keyword_list)} 개 단어')\n",
    "print(f'{keyword_list[:10]}.... \\n')\n",
    "\n",
    "translated_keyword_list = key._map_english_to_korean(keyword_list)\n",
    "print(f'3. 영단어를 한글로 변환(ex python -> 파이썬) -> {len(translated_keyword_list)} 개 단어')\n",
    "print(f'{translated_keyword_list[:10]}.... \\n')\n",
    "\n",
    "refined_keyword_list = key._eliminate_min_count_words(translated_keyword_list, min_count)\n",
    "print(f'4. 최소 2번이상 반복 사용되는 단어만 추출 -> {len(refined_keyword_list)} 개 단어')\n",
    "print(f'{refined_keyword_list[:10]}.... \\n')\n",
    "\n",
    "result = list(filter(lambda x: len(x) >= min_length, refined_keyword_list))\n",
    "print(f'5. 단어 길이가 최소 한개 이상인 단어만 추출 -> {len(result)} 개 단어')\n",
    "print(f'{result[:10]}.... \\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 키워드 뽑기 + 임베딩 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 메뉴명 -- \n",
      " 라면 \n",
      " \n",
      "\n",
      "음식에 대한 키워드 후보 : 6 개 단어\n",
      "['라면', '면', '스프', '다양', '맛', '재료'].... \n",
      " \n",
      "\n",
      "tensor([[-0.2670,  0.1418, -0.5752,  ...,  0.3847,  0.5255, -0.1250],\n",
      "        [-0.4726,  0.4308, -0.7058,  ...,  0.4029,  0.3145, -0.0826],\n",
      "        [-0.3596,  0.3184, -0.4528,  ...,  0.1221,  0.1495,  0.0995],\n",
      "        [-0.2679,  0.4361, -0.5833,  ...,  0.5173,  0.0931, -0.2986]])\n",
      "라면 면 라면은 아시아에서 유명한 인스턴트 면 요리로, 면과 스프로 구성됩니다. 면은 탄력이 있고 쫄깃하며, 다양한 모양과 두께로 제작됩니다. 스프는 라면의 맛을 결정짓는 중요한 재료로, 다양한 맛과 종류가 있습니다. 라면은 추가 재료로 고기, 해산물, 채소, 계란 등을 넣어 풍부하고 맛있게 즐길 수 있습니다. 라면은 전 세계적으로 인기 있는 음식으로, 맛과 편리함으로 알려져 있습니다.\n",
      "{'input_ids': tensor([[    2,  6644,  2672,  6644,  4112,  7198,  4073,  4129,  6963,  4283,\n",
      "         26043,  2672,  7747,  4239,    16,  2672,  4047, 10824,  4239,  6537,\n",
      "          4608,  6216,    18,  8860, 10737,  4007,  3249,  4219, 19561,  4279,\n",
      "          4815,    16,  6417,  4283,  7415,  4047, 14609,  4239,  6815,  4608,\n",
      "          6216,    18, 10824,  4034,  6644,  4234,  2637,  4292,  6393,  4637,\n",
      "          4034,  6397,  4283,  8282,  4239,    16,  6417,  4283, 16970,  7890,\n",
      "          4070,  3249,  4576,  6216,    18,  6644,  4112,  6565,  8282,  4239,\n",
      "          8097,    16, 19733,    16, 11109,    16, 11581,  2446,  4292,  2278,\n",
      "          4025,  9005,  4279,  4219,  7461,  4325,  9019,  2967,  3249,  4576,\n",
      "          6216,    18,  6644,  4112,  3280,  6287,  4199, 10749,  6886,  3249,\n",
      "          4034,  6871, 10749,    16, 16970,  9754,  4418, 10749,  8618,  3249,\n",
      "          4576,  6216,    18,     3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "tensor([[ 3.1711e-01,  1.1379e-01, -4.8309e-01, -1.1232e-01, -3.6001e-02,\n",
      "          5.9059e-02, -5.8316e-02,  1.4287e-01,  4.0494e-02, -1.7399e-01,\n",
      "         -2.2272e-01, -7.5662e-02, -1.2309e-02, -9.0918e-02, -1.0263e-01,\n",
      "          1.8627e-01,  1.2259e-01, -1.0406e-01, -2.8354e-02,  4.6844e-01,\n",
      "         -5.6492e-02, -5.5556e-03,  2.6757e-01,  1.0842e-01, -1.4065e-01,\n",
      "          1.8061e-01, -8.5842e-02,  3.8006e-02, -8.0092e-02, -1.3458e-01,\n",
      "          9.2551e-02, -3.7567e-02,  2.0703e-01,  1.3289e-01,  1.6903e-01,\n",
      "          6.4189e-03, -8.4749e-02, -1.5531e-01, -6.7640e-02, -1.7869e-02,\n",
      "         -1.1915e-01, -3.8458e-01,  1.3234e-01, -3.0687e-01,  1.2486e-03,\n",
      "         -8.2935e-02, -5.7102e-02, -5.8923e-02, -9.4884e-02, -2.1362e-01,\n",
      "         -5.7013e-01,  1.2498e-01, -1.3111e-01,  9.0869e-02, -8.2897e-02,\n",
      "         -1.4300e-01,  4.4646e-01, -4.5281e-02,  4.4421e-01,  2.1075e-01,\n",
      "          2.0485e-01, -1.5626e-01,  3.4432e-01,  1.5451e-01, -8.8715e-02,\n",
      "          8.7315e-02,  1.6273e-01,  1.0998e-01, -5.4624e-01, -5.0384e-02,\n",
      "         -2.2110e-01,  3.5896e-02, -1.0393e-01,  1.5713e-01, -3.3502e-01,\n",
      "         -5.5073e-02, -2.8216e-02,  1.0535e-01, -1.5434e-01, -4.0293e-02,\n",
      "         -3.5641e-01, -4.4408e-02,  1.5700e-01, -3.6033e-01,  3.8529e-02,\n",
      "         -8.8560e-02,  6.7831e-02,  1.3929e-01, -9.7753e-02, -1.9323e-01,\n",
      "         -9.9212e-02,  3.0901e-01, -7.6025e-02, -2.6125e-01, -8.9678e-02,\n",
      "         -5.5187e-02,  4.7390e-02, -7.0763e-02, -1.5208e-01,  4.9302e-02,\n",
      "          5.2456e-02,  1.9626e-01, -1.9686e-01, -2.7200e-01, -1.1811e-01,\n",
      "          2.7556e-01, -3.9004e-01,  1.8405e-02, -4.3492e-01, -7.9236e-01,\n",
      "          2.0893e-01, -9.2179e-02, -3.8420e-02,  5.8031e-02, -2.8322e-01,\n",
      "         -2.8163e-02,  9.9066e-02, -9.9613e-02,  8.6784e-02,  3.3198e-02,\n",
      "         -2.0679e-01, -1.3356e-01, -1.2515e-01, -3.3570e-01, -1.5016e-01,\n",
      "         -4.4038e-02,  1.1640e-01, -4.6208e-02,  4.9981e-02, -4.7209e-01,\n",
      "         -9.3950e-02,  2.0881e-01, -3.6742e-01, -9.5820e-03,  2.5666e-01,\n",
      "         -4.9232e-02,  1.7691e-01,  1.4453e-01,  1.2822e-01, -3.6427e-01,\n",
      "         -1.5590e-01,  6.1827e-02, -1.7936e-01,  1.3037e-01,  1.4203e-01,\n",
      "         -5.4040e-01,  7.5586e-02, -5.2545e-01, -2.2884e-01, -3.9574e-01,\n",
      "         -3.2145e-02,  5.2902e-02, -2.0986e-01,  3.8158e-02,  1.8791e-01,\n",
      "          8.9675e-02, -4.2424e-02, -2.1108e-01, -1.0186e-02, -1.3634e-01,\n",
      "          3.0246e-01, -1.7295e-02,  1.0152e-01, -3.1240e-03, -1.0061e-01,\n",
      "         -5.4168e-02, -4.0006e-01, -3.7859e-02,  5.8944e-02, -9.2020e-02,\n",
      "          1.4506e-01, -2.9800e-01, -9.0207e-02, -4.1831e-02, -9.9413e-02,\n",
      "          1.5079e-01, -7.5739e-02,  2.0036e-01, -1.1462e-01, -1.1860e-01,\n",
      "         -3.3428e-01,  9.3215e-02,  1.8887e-01,  1.4235e-01, -1.5219e-01,\n",
      "         -1.0380e-01,  2.2922e-01,  2.7364e-02, -1.4334e-01, -2.1560e-01,\n",
      "          3.6863e-02, -5.5707e-02, -1.8411e-01, -1.5417e-01,  2.4552e-01,\n",
      "          2.5025e-01,  6.0285e-02,  1.8966e-01, -7.4149e-02, -2.5863e-01,\n",
      "          1.0347e-02, -2.1295e-01,  1.9598e-02,  4.7057e-03, -1.0142e-02,\n",
      "          5.9506e-02, -5.1088e-01, -3.5983e-01, -5.4345e-02,  1.6940e-01,\n",
      "         -2.4351e-01,  2.0616e-01,  1.9629e-01, -4.3115e-01, -7.3511e-02,\n",
      "          2.4428e-01, -1.9073e-01,  3.6273e-02, -1.2306e-01,  1.5735e-01,\n",
      "         -5.2799e-02,  8.1797e-02,  4.7096e-02, -5.3980e-02,  2.0227e-01,\n",
      "          8.4219e-02, -1.3823e-01, -1.1258e-01, -1.7277e-01, -1.7875e-01,\n",
      "          2.5437e-01,  1.9178e-01, -1.4977e-01,  1.8365e-01,  1.6093e-01,\n",
      "         -3.0181e-01,  2.0851e-01, -2.1698e-01, -9.1130e-02, -3.1181e-01,\n",
      "         -3.6346e-01,  2.6263e-02, -3.5835e-01, -1.1473e-01,  6.0636e-02,\n",
      "         -2.6136e-01, -1.0727e-01, -4.5543e-01,  4.1868e-02,  9.6539e-02,\n",
      "          1.9189e-02,  2.8591e-01, -1.3164e-01, -1.8238e-01,  4.8927e-02,\n",
      "         -2.9642e-02, -5.9296e-03, -6.9992e-02,  3.5228e-01,  8.7127e-02,\n",
      "          1.8245e-01, -6.3664e-02,  1.1591e-01, -1.0945e-01,  8.7850e-02,\n",
      "         -9.7228e-02,  4.1317e-02,  2.9073e-02,  4.2598e-02,  2.5352e-01,\n",
      "          1.9274e-01,  1.2742e-01, -1.9315e-01, -1.6710e-01, -3.3397e-01,\n",
      "          3.2559e-01,  8.1815e-02,  2.8033e-02,  5.2894e-03,  1.0299e-01,\n",
      "         -3.7897e-01,  2.4089e-02,  5.0123e-02,  9.3035e-02,  4.6305e-02,\n",
      "          1.1681e-01, -5.9901e-02,  2.0409e-01,  8.3301e-02, -6.8045e-02,\n",
      "          3.9549e-01, -6.1917e-02, -1.4419e-01, -1.5648e-01,  3.5089e-01,\n",
      "         -1.7826e-01,  3.0467e-01, -2.4907e-01, -2.7800e-01, -6.3908e-02,\n",
      "         -2.9605e-01, -1.6034e-01, -6.5744e-03, -1.5487e-02, -1.6270e-01,\n",
      "          3.6170e-01,  1.6252e-01, -1.4656e-01, -2.6452e-01,  5.8101e-02,\n",
      "          7.3234e-02,  1.4417e-02,  7.6180e-02, -2.8831e-01, -7.9321e-02,\n",
      "          1.0972e-01, -1.6962e-01, -2.1752e-01,  3.1687e-01, -3.7647e-02,\n",
      "          2.7699e-03,  3.4656e-02, -5.5160e-02, -1.7676e-01, -6.4214e-02,\n",
      "         -9.3920e-02, -1.0057e-01,  7.5560e-02, -3.5094e-01, -4.1900e-01,\n",
      "          4.4962e-03,  6.6354e-02,  1.3128e-01, -1.6322e-01, -2.3285e-01,\n",
      "         -1.7036e-01,  6.7933e-02,  1.2341e+00, -9.2153e-02,  1.2356e-01,\n",
      "         -1.7461e-01, -9.9630e-02, -1.8359e-01,  1.1954e-01,  7.7230e-02,\n",
      "          1.8176e-02,  1.0503e-02,  4.7792e-02, -3.4042e-01,  4.9778e-02,\n",
      "          7.3463e-02, -3.4250e-02,  2.4019e-01, -1.5430e-01, -3.4446e-01,\n",
      "         -1.0589e-01,  2.0978e-01, -9.7104e-02, -3.9002e-01,  8.6578e-02,\n",
      "         -2.0330e-01, -1.5952e-01, -6.2617e-01, -4.2518e-02, -3.2031e-01,\n",
      "          6.3669e-02, -2.5409e-01, -2.2584e-01, -1.1599e-01,  1.2123e-01,\n",
      "         -4.1879e-02,  1.2372e-01,  4.1538e-03,  3.3394e-01, -9.5645e-02,\n",
      "         -4.7032e-02, -4.1022e-03, -2.9749e-01, -1.4585e-01, -4.8856e-01,\n",
      "          1.3287e-01, -8.4705e-02, -3.1455e-01,  2.0413e-01,  2.9677e-01,\n",
      "         -1.3349e-01,  3.6923e-02, -1.5918e-02,  9.1116e-02,  1.8812e-02,\n",
      "          9.6875e-02,  9.3404e-02, -9.5124e-02,  3.0744e-01, -1.8864e-01,\n",
      "         -1.3628e-01,  4.0167e-01, -2.8077e-01,  2.1887e-01, -1.2224e-01,\n",
      "         -1.0724e-01, -2.6613e-02,  1.4375e-01, -1.0510e-01, -2.6197e-02,\n",
      "         -2.0773e-01,  1.1899e-01, -1.3372e-02,  1.8154e-01, -9.8893e-02,\n",
      "         -2.9823e-02,  1.2990e-02, -8.2315e-02, -7.3052e-02, -1.3109e-01,\n",
      "         -1.1353e-01,  3.4740e-02,  1.7969e-02, -3.8923e-01, -4.9934e-02,\n",
      "         -1.8231e-01,  3.5061e-02, -5.1187e-01, -5.7327e-03, -2.3060e-02,\n",
      "         -2.4290e-01, -5.3925e-01,  1.4251e-01, -1.0394e-01,  5.6872e-02,\n",
      "          6.6206e-02, -2.4872e-01, -2.8064e-01, -2.2479e-01, -4.6112e-01,\n",
      "         -8.0431e-03, -1.6204e-01,  1.8824e-01, -4.3216e-02,  1.7142e-01,\n",
      "          3.6636e-01, -3.8284e-02,  1.7861e-01, -2.8575e-01,  3.2796e-02,\n",
      "          2.8024e-01, -2.1734e-01, -3.7845e-02, -3.1355e-01, -3.1314e-01,\n",
      "         -9.2554e-02, -1.2816e-01,  1.5476e-01, -2.0418e-01,  1.6918e-01,\n",
      "         -4.3155e-02,  1.9075e-01,  2.8832e-01, -9.5693e-02, -3.8939e-01,\n",
      "         -1.8058e-01,  8.3316e-02, -4.4176e-02, -4.6221e-02, -1.2922e-01,\n",
      "         -2.7689e-01,  1.0144e-01,  1.1216e-01, -2.3871e-01,  6.5366e-02,\n",
      "         -3.1961e-01,  3.9502e-01,  6.1004e-03, -2.4256e-01,  2.2818e-01,\n",
      "         -6.8526e-02,  1.9753e-01, -5.0840e-03, -2.4196e-01,  2.0442e-01,\n",
      "         -2.2694e-01,  1.1348e-01, -1.1221e-01, -1.8132e-02, -6.2484e-03,\n",
      "         -2.2515e-01, -5.6471e-02, -4.9659e-02,  5.0885e-02, -8.0849e-02,\n",
      "         -5.4839e-02, -1.4505e-01,  1.7853e-01,  1.6801e-02, -5.9805e-02,\n",
      "         -5.4069e-01, -6.4291e-02, -1.4406e-01, -1.3310e-01, -1.6259e-02,\n",
      "         -1.3158e-01,  2.6756e-03, -1.6499e-01,  2.0796e-02, -9.2868e-02,\n",
      "         -2.4186e-02, -2.3640e-02, -1.4702e-01, -3.9739e-01,  1.5852e-01,\n",
      "         -1.9677e-01,  3.6646e-01, -2.8611e-02, -7.9095e-02, -1.5310e-01,\n",
      "          1.2352e-01, -9.3391e-02, -1.2596e-01, -4.6175e-01, -3.5299e-01,\n",
      "          1.1124e-01, -3.7391e-02,  5.3835e-02, -1.3914e-01, -5.1774e-02,\n",
      "          1.1156e-01,  2.4517e-02, -4.0856e-02, -1.3078e-01,  3.7526e-02,\n",
      "          3.3711e-02, -4.6766e-02, -1.7654e-01,  1.4175e-01,  2.2629e-01,\n",
      "         -4.1589e-01, -1.9108e-01, -3.4887e-01, -3.7477e-02, -1.5936e-01,\n",
      "          3.4316e-02, -3.3234e-01,  2.1710e-01,  2.8643e-01, -4.3632e-02,\n",
      "         -3.3331e-01,  1.3898e-01, -1.2812e-01, -3.3601e-01,  3.7871e-01,\n",
      "         -4.9051e-01,  5.2150e-02, -1.4194e-01, -1.5845e-01,  1.2183e-01,\n",
      "         -1.8386e-02, -5.5991e-03,  1.8129e-01,  1.7791e-01, -1.5102e-01,\n",
      "         -1.1267e-02,  1.5759e-02, -3.7347e-01, -1.1935e-02, -3.7793e-02,\n",
      "          2.8494e-01, -1.7741e-01, -3.1537e-02,  9.6046e-02,  3.5457e-01,\n",
      "         -1.4044e-01,  5.5729e-01,  1.1685e-01,  9.9905e-02,  2.1088e-01,\n",
      "         -2.6899e-01, -2.6871e-01,  4.3012e-02,  8.9381e-02, -1.8544e-01,\n",
      "          4.3238e-01,  2.0130e-01,  1.6886e-01,  3.9123e-01, -9.5306e-02,\n",
      "         -1.4321e-01, -2.0978e-01,  9.3536e-02, -2.4923e-01,  2.1357e-01,\n",
      "         -3.1885e-01, -3.4251e-02,  5.9109e-02, -1.6278e-01,  7.5011e-02,\n",
      "          7.1397e-02, -2.7984e-01,  1.7369e-01, -9.1058e-02,  4.9192e-01,\n",
      "         -5.2196e-02,  2.0203e-01,  3.1854e-01, -1.3396e-01, -2.5830e-01,\n",
      "         -3.9718e-01, -2.0192e-01,  8.9786e-02,  2.5509e-02, -2.7304e-02,\n",
      "          1.1763e-01,  1.7131e-01,  1.5411e-01,  1.0963e+00, -3.1857e-02,\n",
      "          1.0246e-01,  1.5268e-01, -1.3268e-01, -1.2932e-01, -2.8957e-01,\n",
      "          1.0412e-01, -2.9620e-01, -4.4116e-02, -1.5723e-01, -1.2704e-01,\n",
      "         -1.6648e-02,  3.7008e-02,  1.3826e-01, -2.8999e-01,  5.5756e-01,\n",
      "         -1.2024e-01,  2.4277e-01, -9.7916e-02,  4.9838e-01, -6.7974e-02,\n",
      "         -2.2004e-02, -1.5910e-01,  7.4736e-03, -9.7862e-02, -1.0053e-01,\n",
      "          5.1143e-02, -3.6070e-02,  2.4849e-01,  2.4754e-01,  5.6671e-01,\n",
      "         -2.8477e-02, -2.5556e-02,  2.9941e-01, -1.8250e-01, -2.7786e-02,\n",
      "          2.8012e-02, -1.4250e-01, -2.0362e-01, -2.2539e-01,  4.7422e-02,\n",
      "         -8.8728e-02, -8.1098e-02,  6.7562e-02, -3.8557e-01, -1.7555e-03,\n",
      "         -9.1883e-02,  2.8711e-02, -3.6787e-01,  1.0350e-01,  3.4748e-02,\n",
      "         -1.9661e-01,  1.3889e-01, -5.6667e-02, -5.5855e-02, -2.0182e-01,\n",
      "         -2.0511e-01, -3.4882e-01,  2.8010e-01, -1.8345e-01,  2.0141e-02,\n",
      "          1.3208e-01, -4.1482e-01, -2.2991e-02, -1.3548e-01, -1.3385e-01,\n",
      "          5.7047e-02, -1.4929e-01, -5.3012e-02, -1.3352e-01, -3.4109e-01,\n",
      "         -1.7456e-01,  2.2246e-01,  5.2756e-02, -1.7336e-01, -1.0280e-01,\n",
      "         -2.6811e-01,  1.3549e-01,  4.8748e-02, -4.4868e-01, -1.4836e-01,\n",
      "          7.3403e-02, -3.0308e-02,  9.1780e-02, -1.1095e-01, -2.5876e-01,\n",
      "         -4.9421e-01, -2.5993e-01, -1.9521e-01, -3.1136e-02, -4.9382e-01,\n",
      "          1.2674e-02, -1.2237e-01,  2.5718e-02,  1.6669e+01, -5.5584e-01,\n",
      "         -3.0724e-01,  5.7761e-02,  1.3638e-01, -3.1703e-01, -2.1178e-01,\n",
      "         -1.7370e-01, -6.1127e-01, -5.9840e-03,  9.1421e-02, -1.4358e-01,\n",
      "         -1.3796e-01,  1.4759e-01,  1.6516e-01, -1.9122e-02,  1.6580e-01,\n",
      "          1.7277e-01,  1.5697e-01,  3.5669e-01, -1.2785e-01, -1.7112e-01,\n",
      "         -1.4096e-01, -6.0926e-02, -8.7051e-02, -1.2752e-01,  2.8255e-01,\n",
      "         -1.4344e-01, -7.4297e-02,  3.5124e-01, -1.0974e-01, -2.0515e-01,\n",
      "          2.9482e-01,  2.1268e-01,  3.7115e-01, -2.2060e-01, -1.5607e-01,\n",
      "         -3.7570e-01,  1.8851e-01, -1.1192e-01, -3.8316e-01,  2.1553e-01,\n",
      "          2.4257e-01, -7.2000e-02, -7.0444e-02, -2.0317e-02, -8.5124e-03,\n",
      "          3.0258e-01, -2.0194e-02,  5.4162e-02, -4.6052e-01, -1.2788e-01,\n",
      "         -8.2419e-01,  1.1026e-01, -1.8674e-01,  3.4303e-03,  1.3306e-01,\n",
      "         -5.2928e-02,  6.2703e-03, -6.2718e-02]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "doc = scraping_result.iloc[0]\n",
    "\n",
    "print(f'-- 메뉴명 -- \\n {doc.food_name} \\n \\n')\n",
    "\n",
    "keyword_list = extract_keyword_list_in_main(doc)\n",
    "print(f'음식에 대한 키워드 후보 : {len(result)} 개 단어')\n",
    "print(f'{result[:10]}.... \\n \\n')\n",
    "\n",
    "keyword_embedding = create_keyword_embedding_in_main(doc)\n",
    "doc_embedding = create_doc_embedding_in_main(doc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 코사인 유사도순으로 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 키워드 추출 결과(20개 요약)--\n",
      "[('라면', 0.85003704), ('다양', 0.8180337), ('재료', 0.8042269), ('스프', 0.7779288)]\n"
     ]
    }
   ],
   "source": [
    "co_sim_score = key._calc_cosine_similarity(doc_embedding, keyword_embedding).flatten()\n",
    "\n",
    "keyword = dict(zip(keyword_list, co_sim_score))\n",
    "\n",
    "sorted_keyword = sorted(keyword.items(), key=lambda k: k[1], reverse=True)\n",
    "\n",
    "print(f'-- 키워드 추출 결과(20개 요약)--')\n",
    "pprint(sorted_keyword[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라면 면 라면은 아시아에서 유명한 인스턴트 면 요리로, 면과 스프로 구성됩니다. 면은 탄력이 있고 쫄깃하며, 다양한 모양과 두께로 제작됩니다. 스프는 라면의 맛을 결정짓는 중요한 재료로, 다양한 맛과 종류가 있습니다. 라면은 추가 재료로 고기, 해산물, 채소, 계란 등을 넣어 풍부하고 맛있게 즐길 수 있습니다. 라면은 전 세계적으로 인기 있는 음식으로, 맛과 편리함으로 알려져 있습니다.\n",
      "{'input_ids': tensor([[    2,  6644,  2672,  6644,  4112,  7198,  4073,  4129,  6963,  4283,\n",
      "         26043,  2672,  7747,  4239,    16,  2672,  4047, 10824,  4239,  6537,\n",
      "          4608,  6216,    18,  8860, 10737,  4007,  3249,  4219, 19561,  4279,\n",
      "          4815,    16,  6417,  4283,  7415,  4047, 14609,  4239,  6815,  4608,\n",
      "          6216,    18, 10824,  4034,  6644,  4234,  2637,  4292,  6393,  4637,\n",
      "          4034,  6397,  4283,  8282,  4239,    16,  6417,  4283, 16970,  7890,\n",
      "          4070,  3249,  4576,  6216,    18,  6644,  4112,  6565,  8282,  4239,\n",
      "          8097,    16, 19733,    16, 11109,    16, 11581,  2446,  4292,  2278,\n",
      "          4025,  9005,  4279,  4219,  7461,  4325,  9019,  2967,  3249,  4576,\n",
      "          6216,    18,  6644,  4112,  3280,  6287,  4199, 10749,  6886,  3249,\n",
      "          4034,  6871, 10749,    16, 16970,  9754,  4418, 10749,  8618,  3249,\n",
      "          4576,  6216,    18,     3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "키워드 추출 예시\n",
      "\n",
      "메뉴명 :  라면\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>라면</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>다양</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>재료</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>스프</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0\n",
       "0  라면\n",
       "1  다양\n",
       "2  재료\n",
       "3  스프"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract keywords\n",
    "docs_keywords = extract_keyword_in_main(scraping_result.iloc[[0]])\n",
    "\n",
    "# result\n",
    "result = pd.DataFrame(docs_keywords)\n",
    "\n",
    "print('키워드 추출 예시\\n')\n",
    "print('메뉴명 : ', scraping_result.iloc[0].food_name)\n",
    "pd.DataFrame(result.keywords.values[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
